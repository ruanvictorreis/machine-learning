{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Mútipla com NumPy (Vetorizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$RSS(\\mathbf{w})=(y-{\\mathbf{H}\\mathbf{w}})^T(y-{\\mathbf{H}\\mathbf{w}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_rss_vectorized(w, X, Y):\n",
    "    res = Y - np.dot(X,w)\n",
    "    totalError = np.dot(res.T,res)\n",
    "    return totalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current, X, Y, learningRate):\n",
    "    res =  Y - np.dot(X, w_current)\n",
    "    gradient = np.dot(-2*(X.T), res)\n",
    "    new_w = w_current - learningRate * gradient\n",
    "    return [new_w, gradient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X, Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    gradient = np.array([np.inf,np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "    i = 0\n",
    "    while (np.linalg.norm(gradient)>=epsilon):\n",
    "        w, gradient = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        if i % 1000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i,compute_mse_vectorized(w, X, Y)))\n",
    "        i+= 1\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at w0 = [ 0.], w1 = [ 0.], w2 = [ 0.], w3 = [ 0.], w4 = [ 0.], w5 = [ 0.], error = [[ 4794.2359393]]\n",
      "Running...\n",
      "MSE na iteração 0 é de [[ 15.39415211]]\n",
      "MSE na iteração 1000 é de [[ 0.43036269]]\n",
      "MSE na iteração 2000 é de [[ 0.42891282]]\n",
      "MSE na iteração 3000 é de [[ 0.42766679]]\n",
      "MSE na iteração 4000 é de [[ 0.42650933]]\n",
      "MSE na iteração 5000 é de [[ 0.42543391]]\n",
      "MSE na iteração 6000 é de [[ 0.42443472]]\n",
      "MSE na iteração 7000 é de [[ 0.42350635]]\n",
      "MSE na iteração 8000 é de [[ 0.42264379]]\n",
      "MSE na iteração 9000 é de [[ 0.42184238]]\n",
      "MSE na iteração 10000 é de [[ 0.42109776]]\n",
      "MSE na iteração 11000 é de [[ 0.42040593]]\n",
      "MSE na iteração 12000 é de [[ 0.41976314]]\n",
      "MSE na iteração 13000 é de [[ 0.41916591]]\n",
      "MSE na iteração 14000 é de [[ 0.41861102]]\n",
      "MSE na iteração 15000 é de [[ 0.41809545]]\n",
      "MSE na iteração 16000 é de [[ 0.41761644]]\n",
      "MSE na iteração 17000 é de [[ 0.41717137]]\n",
      "MSE na iteração 18000 é de [[ 0.41675786]]\n",
      "MSE na iteração 19000 é de [[ 0.41637365]]\n",
      "MSE na iteração 20000 é de [[ 0.41601668]]\n",
      "MSE na iteração 21000 é de [[ 0.41568501]]\n",
      "MSE na iteração 22000 é de [[ 0.41537685]]\n",
      "MSE na iteração 23000 é de [[ 0.41509054]]\n",
      "MSE na iteração 24000 é de [[ 0.41482452]]\n",
      "MSE na iteração 25000 é de [[ 0.41457735]]\n",
      "MSE na iteração 26000 é de [[ 0.41434771]]\n",
      "MSE na iteração 27000 é de [[ 0.41413434]]\n",
      "MSE na iteração 28000 é de [[ 0.4139361]]\n",
      "MSE na iteração 29000 é de [[ 0.41375191]]\n",
      "MSE na iteração 30000 é de [[ 0.41358078]]\n",
      "MSE na iteração 31000 é de [[ 0.41342177]]\n",
      "MSE na iteração 32000 é de [[ 0.41327404]]\n",
      "MSE na iteração 33000 é de [[ 0.41313678]]\n",
      "MSE na iteração 34000 é de [[ 0.41300925]]\n",
      "MSE na iteração 35000 é de [[ 0.41289075]]\n",
      "MSE na iteração 36000 é de [[ 0.41278066]]\n",
      "MSE na iteração 37000 é de [[ 0.41267837]]\n",
      "MSE na iteração 38000 é de [[ 0.41258333]]\n",
      "MSE na iteração 39000 é de [[ 0.41249503]]\n",
      "MSE na iteração 40000 é de [[ 0.41241299]]\n",
      "MSE na iteração 41000 é de [[ 0.41233676]]\n",
      "MSE na iteração 42000 é de [[ 0.41226594]]\n",
      "MSE na iteração 43000 é de [[ 0.41220013]]\n",
      "MSE na iteração 44000 é de [[ 0.41213899]]\n",
      "MSE na iteração 45000 é de [[ 0.41208219]]\n",
      "MSE na iteração 46000 é de [[ 0.41202941]]\n",
      "MSE na iteração 47000 é de [[ 0.41198037]]\n",
      "MSE na iteração 48000 é de [[ 0.41193481]]\n",
      "MSE na iteração 49000 é de [[ 0.41189247]]\n",
      "MSE na iteração 50000 é de [[ 0.41185314]]\n",
      "MSE na iteração 51000 é de [[ 0.4118166]]\n",
      "MSE na iteração 52000 é de [[ 0.41178264]]\n",
      "MSE na iteração 53000 é de [[ 0.4117511]]\n",
      "MSE na iteração 54000 é de [[ 0.41172179]]\n",
      "MSE na iteração 55000 é de [[ 0.41169455]]\n",
      "MSE na iteração 56000 é de [[ 0.41166925]]\n",
      "MSE na iteração 57000 é de [[ 0.41164574]]\n",
      "MSE na iteração 58000 é de [[ 0.4116239]]\n",
      "MSE na iteração 59000 é de [[ 0.4116036]]\n",
      "MSE na iteração 60000 é de [[ 0.41158475]]\n",
      "MSE na iteração 61000 é de [[ 0.41156723]]\n",
      "MSE na iteração 62000 é de [[ 0.41155095]]\n",
      "MSE na iteração 63000 é de [[ 0.41153583]]\n",
      "Gradiente descendente convergiu com w0 = [ 1.57491479], w1 = [ 0.10595852], w2 = [ 0.05388683], w3 = [ 0.16372742], w4 = [ 0.38944508], w5 = [ 0.02228152], error = [[ 0.41152305]]\n",
      "Versão vetorizada rodou em: 1107.5646877288818 ms\n"
     ]
    }
   ],
   "source": [
    "points = np.genfromtxt(\"sample_treino.csv\", delimiter=\",\")\n",
    "points = np.c_[np.ones(len(points)),points]\n",
    "X = points[:,[0, 1, 2, 3, 4, 5]]\n",
    "Y = points[:,6][:,np.newaxis]\n",
    "init_w = np.zeros((6,1))\n",
    "\n",
    "learning_rate = 0.00002\n",
    "epsilon = 0.05\n",
    "\n",
    "print(\"Starting gradient descent at w0 = {0}, w1 = {1}, w2 = {2}, w3 = {3}, w4 = {4}, w5 = {5}, error = {6}\"\n",
    "      .format(init_w[0], init_w[1], init_w[2], init_w[3], init_w[4], init_w[5], compute_rss_vectorized(init_w, X,Y)))\n",
    "print(\"Running...\")\n",
    "\n",
    "tic = time.time()\n",
    "w = gradient_descent_runner_vectorized(init_w, X, Y, learning_rate, epsilon)\n",
    "toc = time.time()\n",
    "print(\"Gradiente descendente convergiu com w0 = {0}, w1 = {1}, w2 = {2}, w3 = {3}, w4 = {4}, w5 = {5}, error = {6}\".\n",
    "      format(w[0], w[1], w[2], w[3], w[4], w[5], compute_mse_vectorized(w,X,Y)))\n",
    "print(\"Versão vetorizada rodou em: \" + str(1000*(toc-tic)) + \" ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.10304143  0.0464367   0.16409834  0.38117843  0.02027816]]\n"
     ]
    }
   ],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "model = ols.fit(X, Y)\n",
    "print (model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
